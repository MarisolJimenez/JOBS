{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the Current Backlog Combined Data\n",
      "Filtering file for EVM\n",
      "Inserting columns\n",
      "Reading the In Play Report\n",
      "Reading ZCM Item Report\n",
      "Reading Fill Rate\n",
      "Reading the Sourcing Rules for EVM\n",
      "Reading Agile List\n",
      "Reading Inter-Org Intransit\n",
      "Reading the shipments\n",
      "ASN file created\n",
      "Reading All Commit_ZCM\n",
      "Reading Xplore Items\n",
      "Creating Red Column\n",
      "Reordering columns\n",
      "--- 22.586510423819224 minutes to create EVM BL---\n",
      "Writing file\n",
      "--- 37.04956984917323 minutes to create EVM BL and write---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import sys, os\n",
    "import glob\n",
    "import time\n",
    "import fnmatch\n",
    "import os\n",
    "import xlwings as xw\n",
    "start_time = time.time()\n",
    "\n",
    "print('Reading the Current Backlog Combined Data')\n",
    "df1 = pd.read_excel(\"dataEVM.xlsx\", header=0, dtype={'PART': str})\n",
    "#df1 = pd.read_excel(\"dataEVM.xlsx\", header=2, dtype={'PART': str,'SSD': str})\n",
    "\n",
    "df1['SSD'] = pd.to_datetime(df1['SSD'])\n",
    "df1['MATL_TYPE']=np.where(df1['MATL_TYPE']== 'Included','Simple',df1['MATL_TYPE'])\n",
    "#df1.MATL_TYPE.unique()\n",
    "\n",
    "df1['Material Avail Date > CRSD'] = np.where(df1['SSD'] > df1['CRSD'], 'Yes', 'No') \n",
    "\n",
    "df1['SHIP_LOC'] = df1['SHIP_LOC'].str[:3] #delete possible dc with an -\n",
    "\n",
    "df1['SHIP_TO'] = df1['SOLD_TO'] #Copy AE column to AF\n",
    "\n",
    "print('Filtering file for EVM')\n",
    "df1 = df1[(df1['EVM_AIT2'] == 'EVM')]\n",
    "#df1 = df1[(df1['SHIP_LOC'] != 'FL1') & (df1['SHIP_LOC'] != 'UK1') & (df1['SHIP_LOC'] != 'VH1')]\n",
    "df1 = df1[(df1['SHIP_LOC'] != 'UK1') & (df1['SHIP_LOC'] != 'VH1')]\n",
    "print('Inserting columns')\n",
    "df1 = df1.drop(['QOH'], axis = 1)\n",
    "df1.rename(columns={'NETTABLE_QOH': 'QOH'},inplace=True)\n",
    "df1['SSD'] = pd.to_datetime(df1['SSD'])\n",
    "df1.insert(2, 'Trilogy Or Merlin', 'MERLIN')\n",
    "#df1.insert(3, 'Material Avail Date > CRSD', '')\n",
    "#df1.insert(4, 'SO Line Dropped to DC for Delivery', '')\n",
    "df1.insert(5, 'SKU Short(QTYs On Hand) DBL & CRSD <=+4', '')\n",
    "df1.insert(6, 'SO Short(QTYs On Hand) DBL & CRSD <=+4', '')\n",
    "#df1.insert(7, 'Missing CRSD Wk', '')\n",
    "df1.insert(8, 'CRSD Days', '')\n",
    "df1.insert(9, 'TPC SKU/DC/WK Key', '')\n",
    "df1.insert(10, 'Missin Commits TPC/ZCM WK2', '')\n",
    "df1[\"SKU DC Key\"]=df1[\"PART\"]+df1[\"SHIP_LOC\"]\n",
    "df1.insert(13, 'Blended ASP $', '')\n",
    "df1.insert(14, 'EXT Part ASP $', '')\n",
    "df1.insert(19, 'Oracle Intransit(Trilogy IR/ISO)', '')\n",
    "df1.insert(20, 'Oracle Intransit(Trilogy=>Merlin or Merlin=>Trilogy)', '')\n",
    "df1.insert(21, 'ZCM ASN QTY Supply', '')\n",
    "df1.insert(22, 'ZCM Commits WK1', '')\n",
    "df1.insert(23, 'ZCM Commits WK2', '')\n",
    "df1.insert(24, 'ZCM Commits WK3', '')\n",
    "df1.insert(25, 'ZCM Commits WK4', '')\n",
    "df1.insert(26, 'ZCM Commits WK5', '')\n",
    "df1.insert(27, 'WK1 TPC Receipt QTY', '')\n",
    "df1.insert(28, 'Valid TPC Supply', '')\n",
    "df1.insert(29, 'TPC Commits WK1', '')\n",
    "df1.insert(30, 'TPC Commits WK2', '')\n",
    "df1.insert(31, 'TPC Commits WK3', '')\n",
    "df1.insert(32, 'TPC Commits WK4', '')\n",
    "df1.insert(34, 'ZCM ASN QTY and WK1 Net Supply', '')\n",
    "df1.insert(35, 'ZCM Net Commits WK2', '')\n",
    "df1.insert(36, 'ZCM Net Commits WK3', '')\n",
    "df1.insert(37, 'Valid TPC Net Supply WK1', 0) #CS\n",
    "df1.insert(38, 'TPC Net Commits WK2', 0) #CT\n",
    "df1.insert(39, 'TPC Net Commits WK3', 0) #CU\n",
    "df1.rename(columns={'SOURCE': 'SOURCE.'},inplace =True) #COLUMNA AZUL EN EXCEL, IE NO SE MANIPULARA\n",
    "df1.insert(41, 'Net Supply capture by CRSD SKU/DC/WK', '')\n",
    "df1.insert(42, 'Missing ASN Supply Due to CRSD WK', '')\n",
    "df1.insert(43, 'Missing Commit Supply Due to CRSD WK', '')\n",
    "df1.insert(44, 'Merlin/Trilogy Missing Supply Total', '')\n",
    "df1.insert(45, 'SKU/DC Total Supply(OH only)', '')\n",
    "df1.insert(46, 'QTY Short to Sales Orders(CUM) Only INV', '')\n",
    "df1.insert(47, 'QTY Short to Sales Orders(NON-CUM) Only INV', '')\n",
    "df1.insert(48, 'EXT Part ASP $ (QTY Short to Sales Orders(NON-CUM) Only INV)', '')\n",
    "df1.insert(49, 'SKU/DC Total Supply(On Hand+ALL ASN)', '')\n",
    "df1.insert(50, 'QTY Short to Sales Orders(CUM) (On Hand+ALL ASN', '')\n",
    "df1.insert(51, 'QTY Short to Sales Orders(NON-CUM) On Hand+ALL ASN', '')\n",
    "df1.insert(52, 'EXT Part ASP $ (QTY Short to Sales Orders(NON-CUM)) On Hand+ALL ASN', '')\n",
    "df1.insert(53, 'SKU/DC Total Supply ALL ASNs+Commits(No Missing Commits)', '')\n",
    "df1.insert(54, 'QTY Short to Sales Orders(CUM) including Missing Commits+Commits+ALL ASNs', '')\n",
    "df1.insert(55, 'QTY Short to Sales Orders(NON-CUM) w/ Commits+Missing Commits+ALL ASNs', '')\n",
    "df1.insert(56, 'EXT Part ASP $ (QTY Short to Sales Orders(NON-CUM)) INV w/ Commits+Missing Commits+ALL ASNs', '')\n",
    "df1.insert(57, 'SKU/DC Total Supply(OH+ALL ASNs+all 3wk Commtsh)', '')\n",
    "df1.insert(58, 'QTY Short to Sales Orders(CUM) OH+ALL ASNs+all 3wk Commts', '')\n",
    "df1.insert(59, 'QTY Short to Sales Orders(NON-CUM) OH+ALL ASNs+all 3wk Commts', '')\n",
    "df1.insert(60, 'EXT Part ASP $ (QTY Short to Sales Orders(NON-CUM)) OH+ALL ASNs+all 3wk Commts', '')\n",
    "len(df1)\n",
    "\n",
    "#lookup Delivery Creation Date\n",
    "print('Reading the In Play Report')\n",
    "df2 = pd.read_csv('In Play Report.csv')\n",
    "df2 = df2[['SO_LINE','Delivery Creation Date']]\n",
    "df2=df2.drop_duplicates(subset='SO_LINE',keep='first') #df.drop_duplicates as some SO LINES have 2 dates\n",
    "#first was kept since thats how it was done in excel\n",
    "df1 = pd.merge(df1, df2, on='SO_LINE', how='left')\n",
    "df1.rename(columns={'Delivery Creation Date':'SO Line Dropped to DC for Delivery'}, inplace=True)\n",
    "#df1['SO Line Dropped to DC for Delivery']=df1['SO Line Dropped to DC for Delivery'].str[:-5]\n",
    "df1['SO Line Dropped to DC for Delivery']=pd.to_datetime(df1['SO Line Dropped to DC for Delivery'])\n",
    "\n",
    "#lookup if it is a ZCM Item \n",
    "print('Reading ZCM Item Report')\n",
    "#df3 = pd.read_excel(\"ZCM Items.xlsx\", dtype={'SKU DC': str})\n",
    "#df3 = df3[['SKU DC','ZCM']]\n",
    "#df3.rename(columns={'SKU DC': 'SKU DC Key','ZCM':'TPC/ZCM Transmit'},inplace=True)\n",
    "\n",
    "df3 = pd.read_excel(\"ZCM Items.xlsx\", dtype={'Zebra PN': str,'Zebra Site':str})\n",
    "df3['SKU DC Key'] = df3['Zebra PN'] + df3['Zebra Site']\n",
    "df3['TPC/ZCM Transmit'] = \"Yes\"\n",
    "df3=df3[['SKU DC Key','TPC/ZCM Transmit']]\n",
    "df3=df3.drop_duplicates()\n",
    "\n",
    "df1 = pd.merge(df1, df3, on='SKU DC Key', how='left')\n",
    "df1['TPC/ZCM Transmit'].fillna('No', inplace = True)\n",
    "\n",
    "#Service Offering\n",
    "#lookup ASP\n",
    "print('Reading Fill Rate')\n",
    "df4 = pd.read_excel(\"Fill Rate.xlsx\",dtype={'Part No': str, 'ASP_Original': float})\n",
    "df4 = df4[['Part No','ASP_Original']]\n",
    "df4.rename(columns={'Part No': 'PART','ASP_Original':'Part ASP $'},inplace=True)\n",
    "df4=df4.drop_duplicates(subset='PART',keep='first')\n",
    "df1 = pd.merge(df1, df4, on='PART', how='left')\n",
    "df1['Part ASP $'].fillna(0, inplace=True)\n",
    "\n",
    "#lookup Sourcing Rule, Buyer, Planner Code\n",
    "print('Reading the Sourcing Rules for EVM')\n",
    "df5 = pd.read_csv('Sourcing Rule EVM.csv', dtype={'SKU DC': str})\n",
    "df5 = df5[['SKU DC','Item Organization - Sourcing Rule','Default Buyer','Planner Code']]\n",
    "df5.rename(columns={'SKU DC': 'SKU DC Key','Item Organization - Sourcing Rule':'Sourcing Rule',\n",
    "                          'Default Buyer':'BUYER.','Planner Code':'PLANNER CODE'},inplace=True)\n",
    "df1 = pd.merge(df1, df5, on='SKU DC Key', how='left')\n",
    "#df1['Sourcing Rule'].fillna(0, inplace=True)#left as empty to replace nulls with other data\n",
    "df1['BUYER.'].fillna(0, inplace=True)\n",
    "df1['PLANNER CODE'].fillna(0, inplace=True) \n",
    "\n",
    "#df1.loc[df1['SKU DC Key'] == \"RFD8500-1000100-USDS2\"]\n",
    "\n",
    "#FILL NAs from Sourcing Rule WITH AGILE LIST\n",
    "print('Reading Agile List')\n",
    "dfagile = pd.read_excel(\"Agile List.xlsx\", dtype={'Item Number': str})\n",
    "df6 = dfagile[['Item Number','Manufacturer Name']]\n",
    "df6.rename(columns={'Item Number': 'PART'},inplace =True)\n",
    "df6=df6.drop_duplicates(subset='PART',keep='first') #df.drop_duplicates\n",
    "#first was kept since thats how it was done in excel\n",
    "df1 = pd.merge(df1, df6, on='PART', how='left')\n",
    "df1['Sourcing Rule'] = df1['Sourcing Rule'].fillna(df1['Manufacturer Name'])#where sourcing rule is empty\n",
    "#this values change to the result of the merge, ie the manufacturer name in agile file\n",
    "df1 = df1.drop(['Manufacturer Name'], axis = 1) #after gettin these values, this column is no longer needed\n",
    "len(df1)\n",
    "\n",
    "#create an auxiliar table with no sourcing rule in agile to look up in Agile EVM\n",
    "dfSourcingRule=df1[df1['Sourcing Rule'].isnull()]\n",
    "dfSourcingRule=dfSourcingRule[['PART','Sourcing Rule']]\n",
    "dfSourcingRule=dfSourcingRule.drop_duplicates() #CREATE NEW INDEXES\n",
    "dfSourcingRule.reset_index(inplace=True)\n",
    "dfSourcingRule.drop(\"index\",axis=1,inplace=True)\n",
    "\n",
    "len(dfSourcingRule) #HOW MANY PARTS WE'LL LOOK FOR IN AGILE EVM\n",
    "for i in dfSourcingRule.index:\n",
    " a=dfSourcingRule['PART'][i]\n",
    " print (\"Look the next part number in Agile EVM\",{a})\n",
    " dfSourcingRule['Sourcing Rule'][i] = input()\n",
    "\n",
    "dfSourcingRule.rename(columns={'Sourcing Rule':'Sourcing Rule1'},inplace=True)\n",
    "df1 = pd.merge(df1, dfSourcingRule, on='PART', how='left')\n",
    "df1['Sourcing Rule'] = df1['Sourcing Rule'].fillna(df1['Sourcing Rule1'])\n",
    "df1 = df1.drop(['Sourcing Rule1'], axis = 1)\n",
    "#FILL NAN WITH INFO FOUND IN AGILE EVM\n",
    "\n",
    "#create XFR column\n",
    "df1['XFR'] = np.where((df1['Sourcing Rule'].isnull()), '',\n",
    "             np.where(df1['Sourcing Rule'].str.contains('Transfer'), 'Yes',\n",
    "             np.where(df1['Sourcing Rule'].str.contains('transfer'), 'Yes', '')))\n",
    "\n",
    "#if Sourcing Rule starts with Make turn MATL_TYPE to bundle\n",
    "#df1['MATL_TYPE'] = np.where(df1['Sourcing Rule'].astype(str).str.startswith('Make'), 'Bundle', df1['MATL_TYPE'])\n",
    "\n",
    "#if MATL_TYPE is Bundle make PART ASP $, UNIT_VAL, TOT_BL all zero\n",
    "df1['Part ASP $'] = np.where(df1['MATL_TYPE'].astype(str).str.startswith('Bundle'), 0, df1['Part ASP $'])\n",
    "df1['UNIT_VAL'] = np.where(df1['MATL_TYPE'].astype(str).str.startswith('Bundle'), 0, df1['UNIT_VAL'])\n",
    "df1['TOT_BL'] = np.where(df1['MATL_TYPE'].astype(str).str.startswith('Bundle'), 0, df1['TOT_BL'])\n",
    "\n",
    "#create Blended ASP and EXT Part ASP\n",
    "df1['Blended ASP $'] = np.where((df1['UNIT_VAL'] > 0), df1['UNIT_VAL'], df1['Part ASP $'])\n",
    "df1['EXT Part ASP $'] = df1['ACTUAL_QTY'] * df1['Blended ASP $']\n",
    "\n",
    "#lookup Oracle Intransit(Trilogy=>Merlin or Merlin=>Trilogy)\n",
    "print('Reading Inter-Org Intransit')\n",
    "df7 = pd.read_csv(\"Inter-Org Intransit.csv\", dtype={'ITEM': str})\n",
    "df7['SKU DC Key'] = df7['ITEM'] + df7['ORG'].str[4:]\n",
    "df7 = pd.pivot_table(df7, values=['DEMAND_SUPPLY_QTY'], index=['SKU DC Key'], aggfunc=np.sum)\n",
    "df1 = pd.merge(df1, df7, on='SKU DC Key', how='left')\n",
    "df1['Oracle Intransit(Trilogy=>Merlin or Merlin=>Trilogy)'] = df1['DEMAND_SUPPLY_QTY']\n",
    "df1['Oracle Intransit(Trilogy=>Merlin or Merlin=>Trilogy)'].fillna(0, inplace=True)\n",
    "\n",
    "df1 = df1.drop(['DEMAND_SUPPLY_QTY'], axis = 1)\n",
    "len(df1)\n",
    "\n",
    "#Merge shipment files together\n",
    "import glob\n",
    "print(\"Reading the shipments\")\n",
    "path = r'C:\\Users\\MJ7255\\Desktop\\Backlog\\INSUMOS ASN' # use your path\n",
    "all_files = glob.glob(path + \"/*.xlsx\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_excel(filename, index_col=None, header=1)\n",
    "    li.append(df)\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "#export ASN file\n",
    "from datetime import date\n",
    "#today = date.today()#tday = str(today.strftime(\"%m/%d/%y\")) #tday='ASNs ' + tday #today\n",
    "#frame.to_excel('ASNs '+str(date.today())+'.xlsx', index=False)\n",
    "frame=frame[['*Zebra PN','*Ship To Site','*Shipped Quantity']]\n",
    "frame['SKU DC Key']=frame[\"*Zebra PN\"] + frame[\"*Ship To Site\"]\n",
    "df11 = pd.pivot_table(frame, values=['*Shipped Quantity'], index=['SKU DC Key'], aggfunc=np.sum)\n",
    "df1 = pd.merge(df1, df11, on='SKU DC Key', how='left')\n",
    "df1['ZCM ASN QTY Supply'] = df1['*Shipped Quantity']\n",
    "df1['ZCM ASN QTY Supply'].fillna(0, inplace=True)\n",
    "df1 = df1.drop(['*Shipped Quantity'], axis = 1)\n",
    "print(\"ASN file created\")\n",
    "#df11.to_excel('ASN PIVOT.xlsx')\n",
    "\n",
    "#lookup weekly ZCM Commits\n",
    "print('Reading All Commit_ZCM')\n",
    "a=fnmatch.filter(os.listdir('.'), 'All Commit_ZCM*')\n",
    "a=a[0]\n",
    "\n",
    "#df12.head()\n",
    "#df1 = df1.drop(['ALL MISSING','Week 1','Week 2','ALL WK 1 & 2'], axis = 1)\n",
    "\n",
    "df12 = pd.read_excel(a, header=1, sheet_name='ZCM COMMITS', dtype={'SKU DC': str})\n",
    "df12 = df12[(df12['Supplier ID'] != 'Supplier ID')] #subset rows with info, there some rows with wronf information, headers in ros and dates in week info\n",
    "df12 = df12.rename(columns={'SKU DC': 'SKU DC Key'})\n",
    "df12 = df12[['SKU DC Key','ALL MISSING','ALL WK 1 & 2','Data Measure','Week 1','Week 2','Week 3','Week 4','Week 5']]\n",
    "\n",
    "df12 = df12.groupby(['SKU DC Key']).sum()\n",
    "df12.sort_values(by='ALL MISSING', ascending=False, inplace=True)\n",
    "\n",
    "df1 = pd.merge(df1, df12, on='SKU DC Key', how='left')\n",
    "df1['ZCM Commits WK1'] = df1['Week 1']\n",
    "df1['ZCM Commits WK1'].fillna(0, inplace=True)\n",
    "df1['ZCM Commits WK2'] = df1['Week 2']\n",
    "df1['ZCM Commits WK2'].fillna(0, inplace=True)\n",
    "df1['ZCM Commits WK3'] = df1['Week 3']\n",
    "df1['ZCM Commits WK3'].fillna(0, inplace=True)\n",
    "df1['ZCM Commits WK4'] = df1['Week 4']\n",
    "df1['ZCM Commits WK4'].fillna(0, inplace=True)\n",
    "df1['ZCM Commits WK5'] = df1['Week 5']\n",
    "df1['ZCM Commits WK5'].fillna(0, inplace=True)\n",
    "\n",
    "df1 = df1.drop(['ALL MISSING','Week 1','Week 2','Week 3','Week 4','Week 5'], axis = 1)\n",
    "\n",
    "#lookup to see if items are Xplore\n",
    "print('Reading Xplore Items')\n",
    "df14 = pd.read_excel(\"Xplore Items.xlsx\", sheet_name='Sheet1', dtype={'Number': str})\n",
    "df14 = df14.rename(columns={'Number': 'PART'})\n",
    "df14 = df14[['PART','MAKE']]\n",
    "df1 = pd.merge(df1, df14, on='PART', how='left')\n",
    "df1['Xplore Make items'] = df1['MAKE']\n",
    "df1['Xplore Make items'].fillna('No', inplace=True)\n",
    "df1 = df1.drop(['MAKE'], axis = 1)\n",
    "\n",
    "#create week functions\n",
    "today = date.today()\n",
    "coming_sunday = today + datetime.timedelta(days=-today.weekday()-1, weeks=1) #this sunday sunday 1\n",
    "coming_sunday = coming_sunday.strftime('%Y-%m-%d') #format it\n",
    "coming_monday = today + datetime.timedelta(days=-today.weekday(), weeks=1)#this monday monday 1\n",
    "coming_monday = coming_monday.strftime('%Y-%m-%d') #format it\n",
    "next_sunday = today + datetime.timedelta(days=-today.weekday()-1, weeks=2)#sunday 2 \n",
    "next_sunday = next_sunday.strftime('%Y-%m-%d') #format it\n",
    "next_monday = today + datetime.timedelta(days=-today.weekday(), weeks=2)#monday2\n",
    "next_monday = next_monday.strftime('%Y-%m-%d') #format it\n",
    "following_sunday = today + datetime.timedelta(days=-today.weekday()-1, weeks=3) #sunday 3\n",
    "following_sunday = following_sunday.strftime('%Y-%m-%d') #format it\n",
    "\n",
    "mask1 = (df1['CRSD'] <= coming_sunday) #filter for wk1\n",
    "mask2 = (df1['CRSD'] >= coming_monday) & (df1['CRSD'] <= next_sunday) #filter for wk2\n",
    "mask3 = (df1['CRSD'] >= next_monday) & (df1['CRSD'] <= following_sunday) #filter for wk3\n",
    "\n",
    "#define in which week the CRSD is, (Week 1, 2, or 3)\n",
    "df1['CRSD WK'] = np.where(mask1, 'WK1',\n",
    "                 np.where(mask2, 'WK2',\n",
    "                 np.where(mask3, 'WK3','')))\n",
    "\n",
    "#JUST LEAVE VALUE IN WKS WHEN MAT TPYE IS SIMPLE\n",
    "df1['CRSD WK']=np.where(df1['MATL_TYPE']== 'Simple',df1['CRSD WK'],'')\n",
    "\n",
    "#COLUMN AB, BLUE, COLUMN USUALLY DONE/COPIED AT THE SAME TIME AS RED COLUMN\n",
    "df1['TPC SKU/DC/WK Key'] = df1[\"SKU DC Key\"] + df1[\"CRSD WK\"]\n",
    "\n",
    "#create the Material Avail Date > CRSD column, COLUMN K\n",
    "df1['CRSD'] = df1['CRSD'].dt.strftime('%#m/%d/%Y')\n",
    "\n",
    "df1['SSD']= df1['SSD'].dt.strftime('%m-%d-%Y')\n",
    "\n",
    "#create the CRSD Days column, COLUMN J\n",
    "df1['DATE'] = pd.to_datetime(df1['DATE'])\n",
    "df1['CRSD'] = pd.to_datetime(df1['CRSD'])\n",
    "df1['CRSD Days'] = (df1['DATE'] - df1['CRSD']).dt.days\n",
    "\n",
    "#create Short(QTYs On Hand) DBL & CRSD <=+4 columns\n",
    "df15 = df1[['SHIP_LOC','Trilogy Or Merlin','CRSD','SO','LINE','SO_LINE','SKU DC Key','MATL_TYPE','ACTUAL_QTY','QOH']]\n",
    "#Select just simple\n",
    "df15 = df15[df15['MATL_TYPE'] == 'Simple']\n",
    "#auixiliar of dates\n",
    "today = date.today()\n",
    "four_days = today + datetime.timedelta(days=3)\n",
    "four_days = four_days.strftime('%Y-%m-%d')\n",
    "#when is less than five days\n",
    "df15 = df15[df15['CRSD'] <= four_days]\n",
    "#auxiliar so it can make a count with the 2nd column\n",
    "df15['QOH_2'] = df15['QOH']\n",
    "\n",
    "#create SKU Short(QTYs On Hand) DBL & CRSD <=+4 PIVOT\n",
    "df16 = pd.pivot_table(data=df15, index=['SKU DC Key'], values=['QOH','QOH_2','ACTUAL_QTY'], aggfunc={'QOH': 'sum', 'QOH_2': 'count', 'ACTUAL_QTY': 'sum'}).reset_index()\n",
    "df16['SKU/DC QOH'] = df16['QOH'] / df16['QOH_2']\n",
    "df16['SKU/DC QOH'] = df16['QOH'] / df16['QOH_2']\n",
    "df16['Short +/-'] = df16['SKU/DC QOH'] - df16['ACTUAL_QTY']\n",
    "df16['SKU Short'] = np.where(df16['Short +/-'] <= 0, 'YES', 'NO')\n",
    "df16 = df16[['SKU DC Key','SKU Short']] #Just keep columns we want\n",
    "df1 = pd.merge(df1, df16, on='SKU DC Key', how='left')\n",
    "df1['SKU Short(QTYs On Hand) DBL & CRSD <=+4'] = df1['SKU Short']\n",
    "df1 = df1.drop(['SKU Short'], axis = 1)\n",
    "df1['SKU Short(QTYs On Hand) DBL & CRSD <=+4'] = np.where((df1['CRSD'] <= four_days) & (df1['MATL_TYPE'] == 'Simple'), df1['SKU Short(QTYs On Hand) DBL & CRSD <=+4'], '')\n",
    "\n",
    "#create SO Short(QTYs On Hand) DBL & CRSD <=+4 PIVOT\n",
    "df15 = pd.merge(df15, df16, on='SKU DC Key', how='left')\n",
    "df17 = pd.crosstab(index=df15[\"SO\"], columns=df15[\"SKU Short\"], values=df15[\"SKU DC Key\"], aggfunc='count').reset_index()\n",
    "df17['SO Short'] = np.where(df17['YES'].isnull(), 'NO', 'YES')\n",
    "df17 = df17[['SO','SO Short']]\n",
    "\n",
    "df1 = pd.merge(df1, df17, on='SO', how='left')\n",
    "df1['SO Short(QTYs On Hand) DBL & CRSD <=+4'] = df1['SO Short']\n",
    "df1 = df1.drop(['SO Short'], axis = 1)\n",
    "df1['SO Short(QTYs On Hand) DBL & CRSD <=+4'] = np.where((df1['CRSD'] <= four_days) & (df1['MATL_TYPE'] == 'Simple'), df1['SO Short(QTYs On Hand) DBL & CRSD <=+4'], '')\n",
    "\n",
    "#create ZCM ASN/Commit Net WK1 supply\n",
    "df1['day_of_wk'] = df1['DATE'].dt.day_name()\n",
    "df1['ZCM ASN/Commit Net WK1 Supply'] = np.where(df1['day_of_wk'] == 'Wednesday', df1['ZCM ASN QTY Supply'] + df1['ZCM Commits WK1'],\n",
    "                                       np.where(df1['day_of_wk'] == 'Thursday', df1['ZCM ASN QTY Supply'] + df1['ZCM Commits WK1'],\n",
    "                                       np.where(df1['day_of_wk'] == 'Friday', df1['ZCM ASN QTY Supply'] + df1['ZCM Commits WK1'],\n",
    "                                       np.where(df1['day_of_wk'] == 'Saturday', df1['ZCM ASN QTY Supply'] + df1['ZCM Commits WK1'],\n",
    "                                       np.where(df1['day_of_wk'] == 'Sunday', df1['ZCM ASN QTY Supply'] + df1['ZCM Commits WK1'],\n",
    "                                       np.where((df1['day_of_wk'] == 'Monday') & (df1['ZCM ASN QTY Supply'] >= df1['ZCM Commits WK1']), df1['ZCM ASN QTY Supply'],\n",
    "                                       np.where((df1['day_of_wk'] == 'Tuesday') & (df1['ZCM ASN QTY Supply'] >= df1['ZCM Commits WK1']), df1['ZCM ASN QTY Supply'], df1['ZCM Commits WK1'])))))))\n",
    "df1 = df1.drop(['day_of_wk'], axis = 1)\n",
    "\n",
    "\n",
    "## 2ND check POINT MARISOL\n",
    "print(\"Creating Red Column\")\n",
    "#CREATE RED COLUMN\n",
    "#THE SKU DC WITH DIFFERENT COMMENTS WILL KEEP ONLY ONE, IF SEVERAL THE WILL BE CONCATANETED\n",
    "df13 = pd.crosstab(index=df1[\"SKU DC Key\"], columns=df1[\"CRSD WK\"], values=df1[\"CRSD WK\"], aggfunc='count').fillna(0)\n",
    "df13 = df13.reset_index()\n",
    "df13.sort_values(by='SKU DC Key', ascending=True, inplace=True)\n",
    "\n",
    "df13['WK1'] = df13['WK1'].astype(int)\n",
    "df13['WK2'] = df13['WK2'].astype(int)\n",
    "df13['WK3'] = df13['WK3'].astype(int)\n",
    "#df13.to_excel('RED COLUMN TABLE1.xlsx', index=False)\n",
    "df13['WK1'] = np.where(df13['WK1'] > 0, 'Yes', 'No')\n",
    "df13['WK2'] = np.where(df13['WK2'] > 0, 'Yes', 'No')\n",
    "df13['WK3'] = np.where(df13['WK3'] > 0, 'Yes', 'No')\n",
    "df13[''] = np.where(df13[''] > 0, 'Yes', 'No')\n",
    "\n",
    "#df13 = df13.drop([''], axis = 1)\n",
    "df13['Missing CRSD Wk'] = np.where((df13['WK1'] == 'No') & (df13['WK2'] == 'No') & (df13['WK3'] == 'No'), 'All Missing Blank',\n",
    "                          np.where((df13['WK1'] == 'No') & (df13['WK2'] == 'Yes') & (df13['WK3'] == 'No') & (df13[''] == 'Yes'), 'Missing WK1,Missing WK3',#\n",
    "                          np.where((df13['WK1'] == 'No') & (df13['WK2'] == 'No') & (df13['WK3'] == 'Yes'), 'All Missing WK3',\n",
    "                          np.where((df13[''] == 'Yes') & (df13['WK2'] == 'Yes') & (df13['WK3'] == 'No'), 'Missing WK3',         \n",
    "                          np.where((df13['WK1'] == 'Yes') & (df13['WK3'] == 'Yes') & (df13['WK2'] == 'No'), 'Missing WK2',\n",
    "                          np.where((df13['WK2'] == 'Yes') & (df13['WK1'] == 'No'), 'Missing WK1', 'Nothing Missing'))))))\n",
    "#df13.to_excel('RED COLUMN TABLE2.xlsx', index=False)\n",
    "df1 = pd.merge(df1, df13, on='SKU DC Key', how='left')\n",
    "df1 = df1.drop(['WK1','WK2','WK3'], axis = 1)\n",
    "\n",
    "df1['DISTY']=''\n",
    "df1['SLSOFF2']=''\n",
    "df1['PSION']=''\n",
    "df1['COMPLETE']=''\n",
    "df1['IR_NUMBER']=''\n",
    "\n",
    "print('Reordering columns')\n",
    "df1 = df1[[\"DATE\",\"THEATRE\",\"SHIP_LOC\",\"Trilogy Or Merlin\",\"ORD_TYPE\",\"SLSOFF2\",\"SLSOFF2_DE\",\"BOOKED\",\"CRSD\",\"CRSD Days\",\n",
    "           \"Material Avail Date > CRSD\",\"SSD\",\"FSSD\",\"DFF_CRSD\",\"SO\",\"LINE\",\"SO_LINE\",\"SO Line Dropped to DC for Delivery\",\n",
    "           \"SKU Short(QTYs On Hand) DBL & CRSD <=+4\",\"SO Short(QTYs On Hand) DBL & CRSD <=+4\",\n",
    "           \"SHIP-SET $'s\",\"ORDER $'s\",\"SHIP_SET\",\"PART\",\"Missing CRSD Wk\",\"CRSD WK\",\"TPC SKU/DC/WK Key\",\"SKU DC Key\",\"TPC/ZCM Transmit\",\"MATL_TYPE\",\n",
    "           \"ACTUAL_QTY\",\"REMAIN_QTY\",\"Part ASP $\",\"Blended ASP $\",\n",
    "           \"EXT Part ASP $\",\"UNIT_VAL\",\"TOT_BL\",\"TOP-FILE $'s\",\"SOLDTO_NO\",\"SOLD_TO\",\"SHIP_TO\",\"SHIP_DESC\",\"HOLD\",\n",
    "           \"DISTY\",\"DISTY_1\",\"TOTAL_ORD\",\"FAMILY\",\"PROD_LINE\",\"CORE\",\"COMPLETE\",\"PO\",\"SOURCE.\",\"Sourcing Rule\",\"XFR\",\"SOURCE_2\",\n",
    "           \"STATUS\",\"CARRIER\",\"SHIP_MTHD\",\"IR_NUMBER\",\"DAYS_OLD\",\"DAYS_OLD2\",\"BUYER.\",\"PLANNER CODE\",\"BUYER\",\"INVC_QTY\",\n",
    "           \"REMAIN_INV\",\"DISTY2\",\"FSSD_CRSD\",\"HOLD_2\",\"REASON\",\"SHIP_QTY\",\n",
    "           \"QOH\",\"Oracle Intransit(Trilogy IR/ISO)\",\"Oracle Intransit(Trilogy=>Merlin or Merlin=>Trilogy)\",\"ZCM ASN QTY Supply\",\n",
    "           \"ZCM Commits WK1\",\"ZCM Commits WK2\",\"ZCM Commits WK3\",\"ZCM Commits WK4\",\"ZCM Commits WK5\",\"WK1 TPC Receipt QTY\",\n",
    "           \"Valid TPC Supply\",\"TPC Commits WK1\",\"TPC Commits WK2\",\"TPC Commits WK3\",\"TPC Commits WK4\",\n",
    "           \"ZCM ASN/Commit Net WK1 Supply\",\n",
    "           \"ZCM ASN QTY and WK1 Net Supply\",\"ZCM Net Commits WK2\",\"ZCM Net Commits WK3\",\"Valid TPC Net Supply WK1\",\n",
    "           \"TPC Net Commits WK2\",\"TPC Net Commits WK3\",\"Missin Commits TPC/ZCM WK2\",\"Net Supply capture by CRSD SKU/DC/WK\",\n",
    "           \"Missing ASN Supply Due to CRSD WK\",\"Missing Commit Supply Due to CRSD WK\",\"Merlin/Trilogy Missing Supply Total\",\n",
    "           \"ORG_BOOK\",\"SKU/DC Total Supply(OH only)\",\"QTY Short to Sales Orders(CUM) Only INV\",\"QTY Short to Sales Orders(NON-CUM) Only INV\",\n",
    "           \"CRSD_WEEK\",\"CRSD_MONTH\",\"CRSD_QTR\",\"SSD_WEEK\",\"SSD_MONTH\",\"SSD_QTR\",\"PSION\",\"COUNTRY\",\"DELINQ\",\"ALIGN\",\"BOOK_WEEK\",\n",
    "           \"BU\",\"SYSTEM\",\"CREATED_BY\",\"DFF_CRSD2\",\"BOOK_CRSD\",\"BOOK_CRSD2\",\"DAYS_OLD3\",\"SUB_FAMILY\",\"CODE_NAME\",\"THEATRE1\",\n",
    "           \"EVM_AIT\",\"HOLD_3\",\"INCO\",\"EVM_AIT2\",\"DELINQ_SSD\",\"DAYS_OLD4\",\"PAY_TERMS\",\"FISC_ZCRD\",\"FISC_SSD\",\"BUSINESS\",\"PRIORITY\",\n",
    "           \"STATE\",\"SUB_LINE\",\"EXT Part ASP $ (QTY Short to Sales Orders(NON-CUM) Only INV)\",\"SKU/DC Total Supply(On Hand+ALL ASN)\",\n",
    "           \"QTY Short to Sales Orders(CUM) (On Hand+ALL ASN\",\"QTY Short to Sales Orders(NON-CUM) On Hand+ALL ASN\",\n",
    "           \"EXT Part ASP $ (QTY Short to Sales Orders(NON-CUM)) On Hand+ALL ASN\",\"SKU/DC Total Supply ALL ASNs+Commits(No Missing Commits)\",\n",
    "           \"QTY Short to Sales Orders(CUM) including Missing Commits+Commits+ALL ASNs\",\"QTY Short to Sales Orders(NON-CUM) w/ Commits+Missing Commits+ALL ASNs\",\n",
    "           \"EXT Part ASP $ (QTY Short to Sales Orders(NON-CUM)) INV w/ Commits+Missing Commits+ALL ASNs\",\"SKU/DC Total Supply(OH+ALL ASNs+all 3wk Commtsh)\",\n",
    "           \"QTY Short to Sales Orders(CUM) OH+ALL ASNs+all 3wk Commts\",\"QTY Short to Sales Orders(NON-CUM) OH+ALL ASNs+all 3wk Commts\",\n",
    "           \"EXT Part ASP $ (QTY Short to Sales Orders(NON-CUM)) OH+ALL ASNs+all 3wk Commts\",\"Xplore Make items\"]]\n",
    "\n",
    "#print('Done')\n",
    "df1.sort_values(by=['SKU DC Key','CRSD'],inplace=True)\n",
    "\n",
    "#CY NEW\n",
    "#Auxiliar to keep only first rows, its false in AUX1\n",
    "#since AUX1 answers to the question, is this a duplicate row?\n",
    "df1['skuduplicates']=df1.duplicated(subset=['SKU DC Key']) #FALSE FOR ALL FIRST APPEARENCE of SKU DC Key,TRUE FOR DUPLICATES\n",
    "#df1['AUX1']=np.where(df1['skuduplicates']== False,df1['skuduplicates'],'')\n",
    "#DUPLICATES FOR SKUDC+WK\n",
    "df1['skuduplicates2']=df1.duplicated(subset=['TPC SKU/DC/WK Key'])\n",
    "\n",
    "df1['AUX'] = np.where((df1['Missing CRSD Wk'] == 'Missing WK1,Missing WK3') & (df1['skuduplicates2']== False) & (df1['CRSD WK']== 'WK2'), \n",
    "                            df1['ZCM Commits WK1'],\n",
    "             np.where((df1['Missing CRSD Wk'] == 'All Missing WK3') & (df1['skuduplicates2']== False) & (df1['CRSD WK']== 'WK3'),\n",
    "                      df1['ZCM Commits WK1'] + df1['ZCM Commits WK2'],\n",
    "             np.where((df1['Missing CRSD Wk'] == 'All Missing Blank') & (df1['skuduplicates']== False),\n",
    "                      df1['ZCM Commits WK1'] + df1['ZCM Commits WK2'] + df1['ZCM Commits WK3'],\n",
    "             np.where((df1['Missing CRSD Wk'] == 'Missing WK1') & (df1['skuduplicates2']== False) & (df1['CRSD WK']== 'WK2'),\n",
    "                      df1['ZCM Commits WK1'],\n",
    "             np.where((df1['Missing CRSD Wk'] == 'Missing WK2') & (df1['skuduplicates2']== False) & (df1['CRSD WK']== 'WK3'),\n",
    "                      df1['ZCM Commits WK2'],\n",
    "             np.where((df1['Missing CRSD Wk'] == 'Missing WK3') & (df1['skuduplicates2']== False) & (df1['CRSD WK']== ''),\n",
    "                      df1['ZCM Commits WK3'],\n",
    "            np.where((df1['Missing CRSD Wk'] == 'Missing WK1,Missing WK3') & (df1['skuduplicates2']== False) & (df1['CRSD WK']== ''),\n",
    "                      df1['ZCM Commits WK3'],0)))))))\n",
    "#COLUMN CY MUTIPLE VLOOKUPS DEPENDING ON RED COLUMN\n",
    "df1['Missing Commit Supply Due to CRSD WK'] = pd.to_numeric(df1['AUX'])\n",
    "df1['Missing Commit Supply Due to CRSD WK'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "#ZCM ASN QTY and WK1 Net Supply CP COLUMN\n",
    "df1['ZCM ASN QTY and WK1 Net Supply'] = np.where( (df1['skuduplicates2']== False) & (df1['CRSD WK'] == 'WK1'),\n",
    "                                                           df1['ZCM ASN/Commit Net WK1 Supply'],0 )\n",
    "\n",
    "#ZCM ASN QTY and WK1 Net Supply CQ COLUMN\n",
    "df1['ZCM Net Commits WK2'] = np.where( (df1['skuduplicates2']== False) & (df1['CRSD WK'] == 'WK2'),\n",
    "                                                           df1['ZCM Commits WK2'],0 )\n",
    "#ZCM ASN QTY and WK1 Net Supply CR COLUMN\n",
    "df1['ZCM Net Commits WK3'] = np.where( (df1['skuduplicates2']== False) & (df1['CRSD WK'] == 'WK3'),\n",
    "                                                           df1['ZCM Commits WK3'],0 )\n",
    "#Net Supply capture by CRSD SKU/DC/WK CW COLUMN  \n",
    "#CP+CQ+CR+CS+CT+CU\n",
    "df1['Net Supply capture by CRSD SKU/DC/WK'] = np.where( df1['skuduplicates2']== False,\n",
    "                                                           df1['ZCM ASN QTY and WK1 Net Supply'] + \n",
    "                                                           df1['ZCM Net Commits WK2'] + df1['ZCM Net Commits WK3'],0 )\n",
    "df1['ZCM ASN QTY Supply'] = pd.to_numeric(df1['ZCM ASN QTY Supply'])\n",
    "df1['Missing Commit Supply Due to CRSD WK'] = pd.to_numeric(df1['Missing Commit Supply Due to CRSD WK'])\n",
    "\n",
    "###########NEW\n",
    "# COLUMN CX =+IF(Z4<>\"Nothing Missing\",CC4,0)\n",
    "#bring the ZCM ASN QTY Supply to the Missing ASN Supply Due to CRSD WK column\n",
    "#Nothing Missing ACCORDING TO RED COLUMN VALUES\n",
    "\n",
    "df1['Missing ASN Supply Due to CRSD WK'] = np.where((df1['Missing CRSD Wk'] == 'All Missing Blank') & (df1['skuduplicates']== False) | (df1['Missing CRSD Wk'] == 'All Missing WK3') & (df1['skuduplicates2']== False) & (df1['CRSD WK']=='WK3') \n",
    "                                                    | (df1['Missing CRSD Wk'] == 'Missing WK1,Missing WK3') & (df1['skuduplicates2']== False) |\n",
    "                                                    (df1['Missing CRSD Wk'] == 'Missing WK1') & (df1['skuduplicates2']== False) & (df1['CRSD WK']=='WK2') | \n",
    "                                                    (df1['Missing CRSD Wk'] == 'Missing WK2') & (df1['skuduplicates2']== False)& (df1['CRSD WK']=='WK3') |\n",
    "                                                    (df1['Missing CRSD Wk'] == 'Missing WK3') & (df1['skuduplicates2']== False) & (df1['CRSD WK']==''), \n",
    "                                                    df1['ZCM ASN QTY Supply'], 0)\n",
    "\n",
    "df1['Missing ASN Supply Due to CRSD WK'] = pd.to_numeric(df1['Missing ASN Supply Due to CRSD WK'])\n",
    "\n",
    "\n",
    "\n",
    "#COLUMN CZ Last column of green/orange bucket, copied formulas from yesterday's file\n",
    "#cz =IF(OR(AA4=\"WK2\",AA4=\"WK3\",AA4=\"\"),CY4,IF(CY4-CX4<0,CX4,CY4))\n",
    "df1['Merlin/Trilogy Missing Supply Total'] = np.where( df1['CRSD WK'] != 'WK1',\n",
    "                                            df1['Missing Commit Supply Due to CRSD WK'],\n",
    "                                            np.where( df1['Missing Commit Supply Due to CRSD WK'] - df1['Missing ASN Supply Due to CRSD WK'] < 0,\n",
    "                                            df1['Missing ASN Supply Due to CRSD WK'], df1['Missing Commit Supply Due to CRSD WK'])) \n",
    "\n",
    "df1['Merlin/Trilogy Missing Supply Total'] = np.where( (df1['Merlin/Trilogy Missing Supply Total'] > 0) & \n",
    "                                                      ((df1['Missing CRSD Wk'] == 'Missing WK2') | (df1['Missing CRSD Wk'] == 'Missing WK3')),\n",
    "                                            df1['Missing Commit Supply Due to CRSD WK'],df1['Merlin/Trilogy Missing Supply Total'])\n",
    "\n",
    "#print(len(df1) & \"number of records\")\n",
    "dfSourcingRule.columns = dfagile.columns\n",
    "agileupdate = dfagile.append(dfSourcingRule)  \n",
    "agileupdate.to_excel('Agile list1.xlsx', index=False) #fix automatized name\n",
    "c=(time.time() - start_time)/60\n",
    "print(\"--- %s minutes to create EVM BL---\" % c)\n",
    "\n",
    "#print(len(df1))\n",
    "print('Writing file')\n",
    "strings = time.strftime(\"%m.%d.%Y\")\n",
    "strings= 'EVM ' + strings\n",
    "b=(\"%s.xlsx\" % strings)\n",
    "df1=df1.drop(['skuduplicates','skuduplicates2','AUX'], axis=1)\n",
    "\n",
    "df1.to_excel(b, sheet_name= 'COMBINED',index=False,startrow=2)\n",
    "c=(time.time() - start_time)/60\n",
    "print(\"--- %s minutes to create EVM BL and write---\" % c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=fnmatch.filter(os.listdir('.'), 'All Commit_ZCM*')\n",
    "a=a[0]\n",
    "#print(a)\n",
    "#print(b)\n",
    "pathtc = \"C:\\\\Users\\\\MJ7255\\\\Desktop\\\\Backlog\\\\Backlog Report SAM\\\\Backlog Report\\\\Untitled Folder\\\\\" + a\n",
    "pathf = \"C:\\\\Users\\\\MJ7255\\\\Desktop\\\\Backlog\\\\Backlog Report SAM\\\\Backlog Report\\\\Untitled Folder\\\\\" + b\n",
    "wbtc = xw.Book(pathtc)\n",
    "wbf = xw.Book(pathf)\n",
    "wstc = wbtc.sheets(1)\n",
    "\n",
    "wstc.api.Copy(After=wbf.sheets(1).api)\n",
    "wbf.save()\n",
    "wbtc.app.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
